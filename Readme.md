# ðŸš€ FastAPI OpenAI Proxy â€“ Quick Start Tutorial

This guide helps new users get started running the **FastAPI OpenAI Proxy** project and a local static client.

---

## ðŸ§© Step 1 â€“ Set up the environment

### ðŸªŸ Windows

```powershell
# 1. Create and activate a virtual environment
py -m venv .venv
.\.venv\Scripts\activate

# 2. Install dependencies
py -m pip install uvicorn
py -m pip install fastapi
py -m pip install httpx
py -m pip install python-dotenv
```

### ðŸŽ macOS / Linux

```bash
# 1. Create and activate a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# 2. Install dependencies
python3 -m pip install uvicorn
python3 -m pip install fastapi
python3 -m pip install httpx
python3 -m pip install python-dotenv
```

---

## ðŸ“‚ Step 2 â€“ Navigate to your project folder

### ðŸªŸ Windows

```powershell
cd C:\Projects\python-openai-api\
```

### ðŸŽ macOS / Linux

```bash
cd ~/Projects/python-openai-api/
```

---

## ðŸ” Step 3 â€“ Create your .env file

This file stores your OpenAI API key and CORS origins.

### ðŸªŸ Windows

```powershell
echo OPENAI_API_KEY=sk-your-openai-key > .env
```

### ðŸŽ macOS / Linux

```bash
echo "OPENAI_API_KEY=sk-your-openai-key" > .env
```

---

## âš™ï¸ Step 4 â€“ Run the FastAPI server

### ðŸªŸ Windows

```powershell
py -m uvicorn fastapi_openai_proxy:app --reload --port 8000
```

### ðŸŽ macOS / Linux

```bash
python3 -m uvicorn fastapi_openai_proxy:app --reload --port 8000
```

ðŸ©º Check health endpoint:
Open your browser and visit â†’ [http://127.0.0.1:8000/health](http://127.0.0.1:8000/health)

Expected output:

```json
{ "status": "ok" }
```

---

## ðŸŒ Step 5 â€“ Run the static client

Put your `chat.html` (or `index.html`) file inside a folder, for example `client/`.

### ðŸªŸ Windows

```powershell
cd client
py -m http.server 5500
```

### ðŸŽ macOS / Linux

```bash
cd client
python3 -m http.server 5500
```

ðŸ§­ Now open your browser and visit:
ðŸ‘‰ [http://127.0.0.1:5500/](http://127.0.0.1:5500/)

---

## âœ… Step 6 â€“ Test the Chat API

In your client JavaScript:

```js
fetch('http://127.0.0.1:8000/api/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({ prompt: 'Hello!', model: 'gpt-4o-mini' }),
})
  .then((res) => res.json())
  .then(console.log);
```

You should see a JSON response with the modelâ€™s reply.

---

## ðŸ§  Common issues

| Problem                    | Fix                                                              |
| -------------------------- | ---------------------------------------------------------------- |
| `No module named uvicorn`  | Install inside venv â†’ `pip install uvicorn`                      |
| `CORS policy` error        | Add your client URL to `ALLOWED_ORIGINS` in `.env`               |
| `401 Authentication Error` | Make sure you use your real **OpenAI API key**, not a proxy key  |
| `.env not loaded`          | Ensure `.env` is in the same folder as `fastapi_openai_proxy.py` |
| `Port already in use`      | Try `--port 8001` or `--port 5501`                               |

---

## ðŸ§¾ Example .env

```
OPENAI_API_KEY=sk-xxxxxYourKeyxxxxx
ALLOWED_ORIGINS=http://127.0.0.1:5500,http://localhost:5500
```
